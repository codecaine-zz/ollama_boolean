name: Release Cross-Platform Binaries

on:
  push:
    tags:
      - 'v*'  # Triggers on version tags like v1.0.0
  workflow_dispatch:  # Allows manual triggering

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            target: bun-linux-x64
            output: ollama_boolean-linux-x64
            artifact: ollama_boolean-linux-x64
          - os: windows-latest
            target: bun-windows-x64
            output: ollama_boolean-windows-x64.exe
            artifact: ollama_boolean-windows-x64.exe
          - os: macos-latest
            target: bun-darwin-x64
            output: ollama_boolean-macos-x64
            artifact: ollama_boolean-macos-x64
          - os: macos-latest
            target: bun-darwin-arm64
            output: ollama_boolean-macos-arm64
            artifact: ollama_boolean-macos-arm64

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Run tests
        run: bun test

      - name: Build binary
        run: bun build --compile --target=${{ matrix.target }} --outfile ${{ matrix.output }} index.ts

      - name: Create release directory
        run: mkdir -p release

      - name: Copy binary to release directory
        shell: bash
        run: |
          if [[ "${{ runner.os }}" == "Windows" ]]; then
            cp ${{ matrix.output }} release/${{ matrix.artifact }}
          else
            cp ${{ matrix.output }} release/${{ matrix.artifact }}
            chmod +x release/${{ matrix.artifact }}
          fi

      - name: Create README for release
        shell: bash
        run: |
          cat > release/README.txt << EOF
          Ollama Boolean Classification Tool
          ==================================
          
          This is a cross-platform binary for the Ollama Boolean Classification tool.
          
          Platform: ${{ matrix.os }}
          Architecture: ${{ matrix.target }}
          
          Usage:
            ${{ matrix.artifact }} "Your question here"
            ${{ matrix.artifact }} --quiet "Your question here"
            ${{ matrix.artifact }} --help
          
          Examples:
            ${{ matrix.artifact }} "Is the sky blue?"
            ${{ matrix.artifact }} --quiet "Can pigs fly?" llama3.2
          
          Requirements:
            - Ollama running locally on http://localhost:11434
            - At least one Ollama model installed (default: qwen3)
          
          For more information, visit: https://github.com/${{ github.repository }}
          EOF

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: release/
          retention-days: 30

  release:
    needs: build
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts

      - name: Create release archive structure
        run: |
          mkdir -p release-final
          for dir in release-artifacts/*/; do
            if [ -d "$dir" ]; then
              artifact_name=$(basename "$dir")
              echo "Processing artifact: $artifact_name"
              
              # Copy binary and readme to final release directory
              cp "$dir"/* release-final/ 2>/dev/null || true
            fi
          done
          
          # List contents for debugging
          echo "Release final contents:"
          ls -la release-final/

      - name: Create GitHub Release
        uses: ncipollo/create-release@v1
        with:
          tag: ${{ github.ref_name }}
          name: Release ${{ github.ref_name }}
          body: |
            ## Ollama Boolean Classification Tool ${{ github.ref_name }}
            
            Cross-platform binaries for the Ollama Boolean Classification tool.
            
            ### Downloads
            
            Choose the appropriate binary for your platform:
            
            - **Linux (x64)**: `ollama_boolean-linux-x64`
            - **Windows (x64)**: `ollama_boolean-windows-x64.exe`
            - **macOS (Intel)**: `ollama_boolean-macos-x64`
            - **macOS (Apple Silicon)**: `ollama_boolean-macos-arm64`
            
            ### Installation
            
            1. Download the appropriate binary for your platform
            2. Make it executable (Linux/macOS): `chmod +x ollama_boolean-*`
            3. Optionally, move to PATH: `sudo mv ollama_boolean-* /usr/local/bin/ollama_boolean`
            
            ### Usage
            
            ```bash
            # Basic usage
            ./ollama_boolean "Is the sky blue?"
            
            # Quiet mode (returns only 0, 1, or 2)
            ./ollama_boolean --quiet "Can pigs fly?"
            
            # With custom model
            ./ollama_boolean "Is this art beautiful?" llama3.2
            
            # Show help
            ./ollama_boolean --help
            ```
            
            ### Requirements
            
            - Ollama running locally on http://localhost:11434
            - At least one Ollama model installed (default: qwen3)
            
            ### What's New
            
            - Cross-platform standalone binaries
            - No runtime dependencies required
            - Full CLI functionality preserved
            - Comprehensive test suite included
            
            For source code and development setup, see the [README](https://github.com/${{ github.repository }}).
          draft: false
          prerelease: false
          files: release-final/*
